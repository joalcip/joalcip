# A Roadmap to Democratic AI

<b> When it comes to AI, we can still take the democratic path—but it is not the default one.</b> Our social institutions—corporations, government, bureaucracy—are not currently equipped to take on this task. Democratic innovation is a public good: it is systematically under-provided without intervention. This is especially true for democratic innovation in governing AI. Practically, it’s hard to develop better decision-making and distribution mechanisms that match the speed, focus, and concentration of resources driving the world’s shiniest technology. It’s hard to improve collective intelligence at the rate we’re improving artificial intelligence. But that’s what we need to do.

<b> We founded the Collective Intelligence Project to find a new default path, and to build a better future.</b> This work requires experimentation, commitment, resources, partnership, and coalition-building. We’re grateful for the opportunity to work alongside, and learn from, inspiring colleagues who share our goal: to ensure that progress, participation, and safety don’t have to trade off. Why democratic AI? We think of democracy as more than deliberation, public input, or elections. At its core, democracy is a set of adaptive, accountable institutions that process and act on decentralized information, provide public goods, and safeguard people’s freedom, wellbeing, and autonomy. When we say democratic AI, we mean an AI ecosystem that does the same, by default. <b>This document is our attempt to concretely describe what can be immediately done, built, researched, advocated for, and funded in 2024 in the AI ecosystem to achieve that goal.</b>

It’s worth saying up front: <b> We do not think this document is exhaustive.</b> We don’t discuss AI’s impact on the nuts and bolts of existing, nation-state democracy. We don’t cover the necessary role of stronger labor movements or a robust and expanded social safety net, nor do we discuss many ways we think AI could be used for direct public benefit, from healthcare to public services to education. We are an R&D lab at heart; our focus here reflects this. Finally, this is a living document. We believe in collective intelligence; naturally, we also believe we’re probably missing something that you know. <b> If you have an idea or a good example that we missed, if you vigorously disagree and are willing to walk us through your reasoning, or if you want to collaborate on the next steps below, please feel free to work with us on this document, or reach out to us at hi@cip.org.</b>

We’re still early, but that doesn’t mean we have much time. If you share this vision, we want to work with you, build with you, and support you. 

Let’s do this.


## Table of Contents

1. [The Destination: What would democratic AI look like in 2030?](#destination)
2. [The Journey: What are our priorities for 2024?](#priorities-2024)
3. [Roadmap Guide: What can I do if I work in…?](#roadmap-guide)
4. [The Roadmap](#roadmap)
5. [Our Starting Point: What did we do last year?](#starting-point)
6. [Future Directions](#future-directions)
    1. [Advance the collective fine-tuning of generative models](#fine-tuning)
    2. [Introduce collective input into more points within the AI lifecycle](#collective-input)
    3. [Connect the open source and democracy communities](#open-source-democracy)
    4. [Expand public input processes geographically](#public-input)
    5. [Build AI-enabled tools for democratic governance](#ai-tools)
    6. [Experiment with institutional governance models](#institutional)
7. [Conclusion](#conclusion)




<a name="destination"> </a>

## The Destination: What would democratic AI look like in 2030?

We expect the world will look quite different in 2030. But here are three pillars
we think are necessary for democratic AI, and provide especially fertile
opportunities for experimentation, advocacy, and research.

This list is by no means exhaustive. Instead, in the spirit of democratic
collaboration, we thought it was important to have a point of view and stake
out a perspective where others may disagree.

1. Our capacity for collective intelligence begins to keep pace with
progress in artificial intelligence. We use AI to improve our systems
for deliberation, translation, facilitation, and preference elicitation; We
expand this to improve interactions within and between institutions, as
well as between institutions and individuals.
Impact: We’ll be much better at understanding and actualizing
collective preferences.

3. Important AI systems are governed by feedback loops of collective
input. We have built the infrastructure to inclusively gather, parse, and
incorporate public input on complex questions surrounding AI. This
includes responsively building AI systems to target real community
needs, and enabling responsive opt-out of AI systems.
Impact: Collective preferences directly inform any high-impact
systems.

5. High-impact sites of AI development are (re)structured to optimize
for the collective interest. The core material inputs to AI (data and
compute) are governed non-monopolistically. Sites of development
and deployment, whether open source movements, corporations,
startups, or government agencies, are subject to checks and balances
to mitigate against power centralization.
Impact: We’re not just gathering collective input, we’ve shifted
incentives and built institutional capacity to actually compel
action based on the public interest.

We also want there to be a variety of models that all sorts of people can use
safely, opt-out guarantees for users, and strong data protection rules — not to
mention many positive use-cases for AI. But these three achievements would
massively change the political economy of AI, and they form a foundation for
our vision.

<a name="priorities-2024"> </a>
## The Journey: What are our priorities for 2024

What are our priorities for 2024?
This list starts off with extremely specific research advances we’re building on,
and then gets increasingly wide-angled. We believe both incremental advances
and reaching for ambitious improvements in collective decision-making are
equally important.

1. Advance collective fine-tuning of frontier models. In 2023, we
prioritized our work on Alignment Assemblies, where we assembled
people and communities to assess, deliberate over, and co-create AI
models that reflected their values. This builds on work CIP and others
have done successfully is a gateway to more democracy in AI.

3. Identify other opportunities for ongoing public input in the AI
lifecycle. There are multiple opportunities in the development,
deployment, and post-deployment of AI to incorporate ongoing public
input. We will continue to develop better methods to assess what
'good' means, and figure out how to integrate the input within the
technology itself in a straightforward and meaningful way.

5. Connect the open source and democracy movements. Efforts to
increase access (open source) to AI, and efforts to increase
participation (democracy) tend to attract different communities, but
we believe that these two worlds – hackers and participedians, to
simplify – need each other, especially when it comes to data
governance, model fine-tuning, and risk assessment.

7. Expand Alignment Assemblies to other parts of the world, and to
other languages. We must continue the push towards greater overlap
between those affected by AI decisions and those making them.

9. Build AI-enabled tools for democratic governance. The future of
democracy could be much better than the past. Building
transformative technology into governance ensures that collective
intelligence processes keep pace with AI and new possibilities for
participation can be unlocked.

11. Experiment with institutional governance models for AI
development. We’re far from the best containers in which to build
transformative technology. If we’re going to achieve collective data
governance, direct stakeholder input, and public accountability, we’ll
need to experiment with new development and funding models.

<a name="roadmap-guide"> </a>
## Roadmap Guide: What can I do if I work in…?
What can I do if I work in…

### AI Research
<ul>
  <li><span> Build participation technology. Create AI-enabled collective
intelligence tools and processes for better collective decision-making,
including translation, moderation, facilitation, and preference
aggregation. (see section 5) </span></li>

<li> Develop more processes for public input into AI systems. Collective
Constitutional AI is an example–innovate on collecting granular
preferences and training models. (see section 1) </li>

<li> Identify new leverage points in the AI lifecycle for collective input.
(see section 2, especially ‘Development’ and ‘Deployment’) </li>

<li> Lead on collective governance of training data and improve the
data supply chain, including opt-out and transparency processes,
self-determination for data laborers, etc.</li>
    
<li> Work with diverse audiences and communities to co-create
models. Engage people from different domain areas (democratic
innovation, open source development, etc.) and geographies to apply
these ideas in practice.</li>

### AI Development
<li> Amplify internal teams already doing research on democratic AI
research. Our Collective Constitutional AI (CCAI) project with
Anthropic and DeepMind’s Habermas Machine are examples. Build
internal leaderboards around success and breadth of public input.
    
<li> Build out access to technology for developing AI-enabled collective
intelligence tools and processes. The future is wild, and we need to
give people access to the best possible tools to improve our ability to
coordinate. (see section 5)</li>

<li> Develop practical principles for embedding public input into
internal organizational decision-making in a meaningful way. (see
section 2)</li>

<li> Explore collective input options for post-deployment monitoring
and feedback. This includes community oversight committees or
councils. (see section 2, especially ‘Post-Deployment’)</li>

<li> Fund research into these topics. OpenAI’s ‘Democratic Inputs to AI’
grant scheme is one possible template for future work.</li>

<li>Include public inputs into internal evaluations and audits. One
example is our work with OpenAI (see section 2, especially
'Deployment’ and ‘Post-Deployment’)</li>

<li> Look at alternative governance mechanisms within your organization
and supply chains. (see section 6)</li>

### Policy, Public Investment, and Regulation

<li> Harness collective intelligence systems to assist with monitoring
and evaluation. This is especially true for socio-technical evaluations,
societal ‘red-lines’, and monitoring societal impacts. (see section 2,
especially ‘Post-Deployment’)</li>

<li> Develop more robust mechanisms to engage the public when
creating standards and regulations. This could enhance problem
identification, solution ideation, and generate broader public buy-in.</li>
(see section 2)</li>

<li> Invest in public AI infrastructure. Building expertise and resources
outside of labs is crucial to ensuring broad public accountability;
investing in applications of AI for the public good requires public sector
AI infrastructure. This should include citizen and stakeholder
engagement from the start, including in the allocation of resources
(compute, data, etc.) and in public sector generative AI rollout
decisions. (see section 2 and section 6)</li>

### Civil Society
<li>Develop and establish new models for data governance. This
includes ideas like data sovereignty experiments or data cooperatives.
(see sections section 2, especially ‘Development’, and section 6)</li>

<li> Support Alignment Assemblies internationally. (see section 4)</li>

<li> Publish a leaderboard that assesses how well AI companies
incorporate the public interest, to support the directing of public
contracts and broader support.</li>

<li> Support more equitable forms of data labor for creating, labeling, and
cleaning data. (see section 2 and section 6)</li>

<li> Shift the political economy of AI development from the bottom-up.
Explore economic models for public interest approaches to
development, deployment, post-deployment, and funding e.g.
cooperatives, crowd-funding, and more. (see section 6)</li>

### Open-Source
<li> Actively connect with the democratic innovation space to create
shared expertise, recognizing that the democratization of access
without governance rights is not enough to ensure the public interest.
(see section 3)</li>

<li> Build AI-enabled tools for collective intelligence. (see section 5)</li>

<li> Explore collective fine-tuning on open source generative models.
(see section 1)</li>

<li> Explore alternative public input mechanisms to open source models.
(see section 2, especially ‘Development’,)</li>

<li> Support Alignment Assemblies internationally. We especially need
technical expertise (see section 4).</li>

<li> Support experimentation with alternative governance
infrastructures, bringing in learnings from open source governance.
(see section 6) </li>


<!--
**joalcip/joalcip** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- 🔭 I’m currently working on ...
- 🌱 I’m currently learning ...
- 👯 I’m looking to collaborate on ...
- 🤔 I’m looking for help with ...
- 💬 Ask me about ...
- 📫 How to reach me: ...
- 😄 Pronouns: ...
- ⚡ Fun fact: ...
-->
